{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Importación al bucket iedatalakeLanding de entidades de Microsoft Dynamics AX\n",
    "## ------------------------------------------------------------------------------\n",
    "##\n",
    "## Las entidades necesarias se extraerán de la base de datos de AX. \n",
    "\n",
    "import sqlalchemy\n",
    "import csv\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import uuid\n",
    "import sys\n",
    "\n",
    "# Importación de opciones de configuración\n",
    "\n",
    "if (os.name == 'nt'):\n",
    "    sys.path.append(os.environ[\"USERPROFILE\"].replace('\\\\', '/') + '/iedatalake/python/config')\n",
    "else: \n",
    "    sys.path.append('/home/ubuntu/iedatalake/python/config')\n",
    "import databaseconfig as dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Proceso, versíón y fecha de ingesta para identificar la ejecución\n",
    "\n",
    "ingestionProcess = 'Ingesta de Entidades AX desde analytics01 en python'\n",
    "ingestionVersion = str(uuid.uuid1())\n",
    "ingestionInitialDate = str(datetime.datetime.now())\n",
    "\n",
    "## Motor SQLAlchemy para la base de datos SQL Server de AX\n",
    "\n",
    "axEngine = sqlalchemy.create_engine(dbc.ax['dialect'] + '+' + dbc.ax['driver'] + '://' \\\n",
    "      + dbc.ax['username'] + ':' + dbc.ax['password'] + '@' \\\n",
    "      + dbc.ax['host'] + '/' + dbc.ax['database'] + dbc.ax['parameters'])\n",
    "\n",
    "## Carpeta auxiliar para depositar los CSVs generados antes de subir\n",
    "\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Procedimiento de importación de una entidad de AX a un fichero CSV local\n",
    "\n",
    "def ImportAXEntity(entityName, csvIndex, **optionalParameters): \n",
    "    \n",
    "    # Ruta del fichero CSV, asumida en una subcarpeta \"data\" en la carpeta donde se ejecuta\n",
    "    # y extensión .csv.gz porque se generará comprimido en formato GZIP\n",
    "    \n",
    "    csvFile = optionalParameters.get('csvFile', 'data/' + entityName + '.csv.gz')\n",
    "        \n",
    "    # Parámetro opcional con el número de registros del bloque a recuperar de forma iterativa\n",
    "    \n",
    "    chunkSize = optionalParameters.get('chunkSize', None)\n",
    "    if (chunkSize == None):\n",
    "        # Si no viene de entrada ningún número de registros, no se limita, poniendo como alcance\n",
    "        # el número total de filas de la tabla de la entidad original\n",
    "        axConnection = axEngine.connect()\n",
    "        df = pd.io.sql.read_sql(\"SELECT COUNT(*) as recuento FROM \" + entityName, axConnection)\n",
    "        chunkSize = int(df[\"recuento\"]) + 1\n",
    "        axConnection.close()\n",
    "    else: \n",
    "        chunkSize = int(chunkSize)\n",
    "\n",
    "    # Convertimos csvIndex a lista, pues llega como una cadena en el parámetro \n",
    "    # con valores separados por coma de la forma 'DATAAREAID, DIMENSIONCODE, NUM' \n",
    "    # dejando el valor original en orderBy para la ordenación en la consulta fraccionada\n",
    "    \n",
    "    orderBy = csvIndex    \n",
    "    csvIndex = csvIndex.replace(' ', '').split(',')    \n",
    "    axConnection = axEngine.connect()\n",
    "    rowsPending = True\n",
    "    offset = 0\n",
    "    while rowsPending:\n",
    "        sqlSentence = \"WITH Results_SQL AS (SELECT \"\\\n",
    "        + \"ROW_NUMBER() OVER \" \\\n",
    "        + \"(ORDER BY \" + orderBy + \") as RowNum, * \" \\\n",
    "        + \"FROM \" + entityName + \") \" \\\n",
    "        + \"SELECT * FROM Results_SQL WHERE  RowNum > \" + str(offset) + \" AND RowNum <=  \" \\\n",
    "        + str(offset + chunkSize)        \n",
    "        chunk = pd.io.sql.read_sql(sqlSentence, axConnection)\n",
    "\n",
    "        print (str(offset)  + \" < RowNum <= \" + str(offset + chunkSize))\n",
    "\n",
    "        # Borramos columna auxiliar RowNum usada para ordenar por el índice\n",
    "        del chunk[\"RowNum\"]\n",
    "        chunk.set_index(csvIndex, inplace = True)        \n",
    "        if (offset == 0):\n",
    "            chunk.to_csv(csvFile, sep = ';', compression = 'gzip', quotechar='|', quoting=csv.QUOTE_MINIMAL, \n",
    "                     encoding = 'utf8')\n",
    "        else:            \n",
    "            chunk.to_csv(csvFile, sep = ';', compression = 'gzip', quotechar='|', quoting=csv.QUOTE_MINIMAL, \n",
    "                     encoding = 'utf8', mode= 'a', header = False)               \n",
    "        offset += chunkSize\n",
    "        if (len(chunk) < chunkSize):\n",
    "            rowsPending = False            \n",
    "        del chunk\n",
    "\n",
    "    axConnection.close()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 < RowNum <= 3677\n"
     ]
    }
   ],
   "source": [
    "ImportAXEntity(entityName = 'LEDGERTABLE', csvIndex = 'DATAAREAID, ACCOUNTNUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 < RowNum <= 180767\n"
     ]
    }
   ],
   "source": [
    "ImportAXEntity(entityName = 'DIMENSIONS', csvIndex = 'DATAAREAID, DIMENSIONCODE, NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 < RowNum <= 300000\n",
      "300000 < RowNum <= 600000\n",
      "600000 < RowNum <= 900000\n",
      "900000 < RowNum <= 1200000\n",
      "1200000 < RowNum <= 1500000\n",
      "1500000 < RowNum <= 1800000\n",
      "1800000 < RowNum <= 2100000\n",
      "2100000 < RowNum <= 2400000\n",
      "2400000 < RowNum <= 2700000\n",
      "2700000 < RowNum <= 3000000\n",
      "3000000 < RowNum <= 3300000\n",
      "3300000 < RowNum <= 3600000\n",
      "3600000 < RowNum <= 3900000\n",
      "3900000 < RowNum <= 4200000\n",
      "4200000 < RowNum <= 4500000\n",
      "4500000 < RowNum <= 4800000\n",
      "4800000 < RowNum <= 5100000\n",
      "5100000 < RowNum <= 5400000\n",
      "5400000 < RowNum <= 5700000\n",
      "5700000 < RowNum <= 6000000\n",
      "6000000 < RowNum <= 6300000\n",
      "6300000 < RowNum <= 6600000\n",
      "6600000 < RowNum <= 6900000\n",
      "6900000 < RowNum <= 7200000\n",
      "7200000 < RowNum <= 7500000\n",
      "7500000 < RowNum <= 7800000\n",
      "7800000 < RowNum <= 8100000\n",
      "8100000 < RowNum <= 8400000\n",
      "8400000 < RowNum <= 8700000\n"
     ]
    }
   ],
   "source": [
    "ImportAXEntity(entityName = 'LEDGERTRANS', csvIndex = 'DATAAREAID, RECID', chunkSize = 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sincronización de carpeta local \"data\" con carpeta \"ax\" del bucket S3 iedatalakelanding\n",
    "## Hace uso de AWSCLI (previamente instalado mediante la instrucción: sudo apt install awscli)\n",
    "\n",
    "ingestionFinalDate = str(datetime.datetime.now())\n",
    "os.system('aws s3 sync data s3://iedatalakelanding/ax --metadata ingestionprocess=\"' + ingestionProcess  \n",
    "          + '\",ingestionversion=\"' + ingestionVersion + '\",ingestioninitialdate=\"' + ingestionInitialDate \n",
    "          + '\",ingestionfinaldate=\"' + ingestionFinalDate + '\",code=\"Ingest-AX-Entities\"');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
